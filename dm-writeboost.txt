dm-writeboost
=============
dm-writeboost provides write-back log-structured caching.
It batches random writes into a big sequential write.


Target Interface
================

Constructor
-----------
writeboost <origin dev> <cache dev>

Status
------

Messages
--------

Technical Features
==================
There are not a few technical features that
distinguishes dm-writeboost from other cache softwares.

# RAM buffer and immediate completion
dm-writeboost allocated RAM buffers of 64MB in total by default.
All of the writes are first stored in one of these RAM buffers
and immediate completion is notified to the upper layer
that is quite fast in few microseconds.

# Metadata durability
After RAM buffer gets full or some deadline comes
dm-writeboost creates segment log
that combines RAM buffer and its metadata.
Metadata have information such as relation between
address in the cache device and
the counterpart in the backing store.
As the segment log is
finally written to persistent cache device,
any data will not be lost due to machine failure.

# Asynchronous log flushing
dm-writeboost has a background worker called flush daemon.
Flushing segment log starts from simply queueing the flush task.
Flush daemon in background
periodically checks if the queue has some tasks
and actually executes the tasks if exists.
The fact that the upper layer doesn't block in queueing the task
can maximizes the write throughput,
that is measured as 259MB/s random writes
with cache device of 266MB/s sequential write which is only 3% loss
and 1.5GB/s theoritically with a fast enough cache like PCI-e SSDs.

# Deferred ack for REQ_FUA or REQ_FLUSH bios
Some applications such as NFS, journal filesystems
and databases often submit SYNC write which
incurs bios flagged with REQ_FUA or REQ_FLUSH.
Handling these unusual bios immediately and thus synchronously
desparately deteriorates the whole throughput.
To address this issue, dm-writeboost handles acks for these bios
lazily or in deferred manner.
Completion related to these bios will not be done
until they are written persistently to the cache device
so this storategy doesn't betray the semantics.
In the worst case scenario, a bio with some of these flags
is completed in deadline period that is configurable
in barrier_deadline_ms in said sysfs.

# Asynchronous and autonomous migration
Some time after a log segment is flushed to the cache device
it will be migrated to the backing store.
Migrate daemon is also a background worker that
periodically checks if log segments to migrate exist.

Restlessly migrating highly burdens backing store
so migration is preferable to execute when the backing store is in lazy time.
A in-core daemon surveils the load of the backing store
and autonomously turns on and off migration according to the load.

Example
=======
To create a logical volume named myLV
backed by /dev/myBacking and
using /dev/myCache as a cache device.

myLV |-- (backing store) /dev/myBacking
     |-- (cache device)  /dev/myCache

sz=`blockdev --getsize /dev/myBacking`
dmsetup create myLV 0 $sz writeboost 5 /dev/myBacking 3

Other PDF documents and Quick start script
are provided in a Github repo.
https://github.com/akiradeveloper/dm-writeboost
